%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

\begin{document}
    \section{Related Work}
    \label{sec:related_work}
     \subsection{PointNet}\cite{PointNet} introduces a novel deep learning architecture specifically designed to handle unordered point directly sets for tasks such as 3D shape classification and segmentation. PointNet's architecture is invariant to input permutation and robust to input transformations, utilizing a combination of multi-layer perceptrons (MLPs) and max pooling to learn global point cloud features. However, the only limitation of PointNet is its inability to capture local structures within the point cloud, as it primarily focuses on global feature learning, which can lead to less accurate segmentation in complex scenes where local geometric details are crucial. Despite this, PointNet is pioneering work directly applying deep learning to point clouds, eliminating the need for voxelization or other preprocessing steps. It demonstrates strong performance across various 3D recognition tasks and opens up new possibilities for deep learning applications in 3D vision.
    
    \subsection{PointClustering}\cite{PointClustering} proposes an unsupervised pre-training method for 3D point cloud representation learning that leverages transformation invariance in clustering. This method learns a generic feature representation by exploiting the inherent clustering structure of point cloud data. However, it primarily focuses on pre-training the representation and does not explore the performance of these representations on downstream tasks. Despite this, the contributions include introducing an unsupervised pre-training method for 3D point cloud representation learning and effectively utilizing the inherent clustering structure of point cloud data to learn a generic feature representation.
    
    \subsection{PointGLR}\cite{PointGLR} introduces a new framework for unsupervised point cloud representation learning. This framework utilizes bidirectional reasoning between local representations at different abstraction hierarchies and the global representation of a 3D object, aiming to capture the underlying semantic knowledge shared between local structures and global shapes in 3D point clouds. Despite its innovative approach, the paper does not address the scalability of the proposed method to large-scale 3D data. Nevertheless, PointGLR makes significant contributions by proposing a novel framework for unsupervised point cloud representation learning, capturing semantic knowledge through bidirectional reasoning, and extending the method to more complex 3D scenes by introducing structural proxies as intermediate-level representations.
    \subsection{PointSeg}

    PointSeg\cite{PointSeg} is a real-time semantic segmentation network designed for 3D LiDAR point cloud data, particularly in autonomous driving scenarios. Unlike PointNet or PointNet++, which are general-purpose, PointSeg specifically optimizes for real-time performance on mobile platforms by utilizing an efficient convolutional architecture that processes spherical projections of the point cloud.
    The network begins by projecting the 3D point cloud onto a 2D spherical image based on range and azimuth, effectively transforming the irregular and unordered 3D data into a dense 2D representation. This allows PointSeg to leverage well-established 2D convolutional neural networks (CNNs) for feature extraction. The architecture adopts an encoder-decoder structure, where the encoder learns rich hierarchical features and the decoder refines spatial resolution for pixel-wise segmentation.
    To maintain contextual awareness and localization precision, PointSeg integrates squeeze-and-excitation (SE) modules and dilated convolutions. These modules enhance feature representation by modeling interdependencies between channels and expanding receptive fields without losing resolution.
    In their experiments, PointSeg demonstrated competitive segmentation performance on large-scale LiDAR datasets such as KITTI. The network achieved a favorable trade-off between accuracy and inference speed, with real-time throughput on embedded GPUs, making it suitable for robotics and autonomous vehicle applications. The authors concluded that spherical projection combined with lightweight convolutional designs enables efficient and effective semantic segmentation of 3D point clouds, especially in scenarios where computational resources are limited.
\end{document}
