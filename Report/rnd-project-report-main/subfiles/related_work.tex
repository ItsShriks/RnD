%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

\begin{document}
    \section{Related Work}
    \label{sec:related_work}
 PointNet\cite{PointNet} introduces a novel deep learning architecture specifically designed to handle unordered point directly sets for tasks such as 3D shape classification and segmentation. PointNet's architecture is invariant to input permutation and robust to input transformations, utilizing a combination of multi-layer perceptrons (MLPs) and max pooling to learn global point cloud features. However, the only limitation of PointNet is its inability to capture local structures within the point cloud, as it primarily focuses on global feature learning, which can lead to less accurate segmentation in complex scenes where local geometric details are crucial. Despite this, PointNet is pioneering work directly applying deep learning to point clouds, eliminating the need for voxelization or other preprocessing steps. It demonstrates strong performance across various 3D recognition tasks and opens up new possibilities for deep learning applications in 3D vision.

PointClustering\cite{PointClustering} proposes an unsupervised pre-training method for 3D point cloud representation learning that leverages transformation invariance in clustering. This method learns a generic feature representation by exploiting the inherent clustering structure of point cloud data. However, it primarily focuses on pre-training the representation and does not explore the performance of these representations on downstream tasks. Despite this, the contributions include introducing an unsupervised pre-training method for 3D point cloud representation learning and effectively utilizing the inherent clustering structure of point cloud data to learn a generic feature representation.
PointGLR\cite{PointGLR} introduces a new framework for unsupervised point cloud representation learning. This framework utilizes bidirectional reasoning between local representations at different abstraction hierarchies and the global representation of a 3D object, aiming to capture the underlying semantic knowledge shared between local structures and global shapes in 3D point clouds. Despite its innovative approach, the paper does not address the scalability of the proposed method to large-scale 3D data. Nevertheless, PointGLR makes significant contributions by proposing a novel framework for unsupervised point cloud representation learning, capturing semantic knowledge through bidirectional reasoning, and extending the method to more complex 3D scenes by introducing structural proxies as intermediate-level representations.
\end{document}
