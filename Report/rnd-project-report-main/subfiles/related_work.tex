%!TEX root = ../report.tex
\documentclass[../report.tex]{subfiles}

\begin{document}
    \section{Related Work}
    \label{sec:related_work}
     \subsection{PointNet}
     Charles et al.\cite{PointNet} introduces a novel deep learning architecture specifically designed to handle unordered point directly sets for tasks such as 3D shape classification and segmentation. PointNet's architecture is invariant to input permutation and robust to input transformations, utilizing a combination of multi-layer perceptrons (MLPs) and max pooling to learn global point cloud features. However, the only limitation of PointNet is its inability to capture local structures within the point cloud, as it primarily focuses on global feature learning, which can lead to less accurate segmentation in complex scenes where local geometric details are crucial. Despite this, PointNet is pioneering work directly applying deep learning to point clouds, eliminating the need for voxelization or other preprocessing steps. It demonstrates strong performance across various 3D recognition tasks and opens up new possibilities for deep learning applications in 3D vision.
    
    \subsection{PointClustering}
    Long et al. \cite{PointClustering} proposes an unsupervised pre-training method for 3D point cloud representation learning that leverages transformation invariance in clustering. This method learns a generic feature representation by exploiting the inherent clustering structure of point cloud data. However, it primarily focuses on pre-training the representation and does not explore the performance of these representations on downstream tasks. Despite this, the contributions include introducing an unsupervised pre-training method for 3D point cloud representation learning and effectively utilizing the inherent clustering structure of point cloud data to learn a generic feature representation.
    
    \subsection{PointGLR}
    Rao et al.â€¯\cite{PointGLR} propose a new framework for learning point cloud representations without supervision. Their method uses bidirectional reasoning, which means it connects and compares features from both small local parts and the overall shape of a 3D object. This helps the model learn the shared semantic patterns between local details and global structures. While the approach is innovative, the paper does not discuss how well it works with large-scale 3D data. Still, PointGLR is a valuable contribution, as it introduces a new way to learn meaningful 3D features and expands the method to more complex scenes by using intermediate structures called structural proxies.
    
    \subsection{PointSeg}

    PointSeg\cite{PointSeg} is a real-time semantic segmentation network designed for 3D LiDAR point cloud data, particularly in autonomous driving scenarios. Unlike PointNet or PointNet++, which are general-purpose, PointSeg specifically optimizes for real-time performance on mobile platforms by utilizing an efficient convolutional architecture that processes spherical projections of the point cloud.
    The network begins by projecting the 3D point cloud onto a 2D spherical image based on range and azimuth, effectively transforming the irregular and unordered 3D data into a dense 2D representation. This allows PointSeg to leverage well-established 2D convolutional neural networks (CNNs) for feature extraction. The architecture adopts an encoder-decoder structure, where the encoder learns rich hierarchical features and the decoder refines spatial resolution for pixel-wise segmentation.
    To maintain contextual awareness and localization precision, PointSeg integrates squeeze-and-excitation (SE) modules and dilated convolutions. These modules enhance feature representation by modeling interdependencies between channels and expanding receptive fields without losing resolution.
    In their experiments, PointSeg demonstrated competitive segmentation performance on large-scale LiDAR datasets such as KITTI. The network achieved a favorable trade-off between accuracy and inference speed, with real-time throughput on embedded GPUs, making it suitable for robotics and autonomous vehicle applications. The authors concluded that spherical projection combined with lightweight convolutional designs enables efficient and effective semantic segmentation of 3D point clouds, especially in scenarios where computational resources are limited.
\end{document}
