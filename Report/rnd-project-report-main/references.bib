@inproceedings{referenceexample,
	title = {{Some Title}},
	author = {Mustermann, Max and Smith, Jane},
	booktitle = {Some Conference},
	pages = {1--8},
	year = {2023}
}

@article{UAV_based_plant_detection,
	title = {{UAV}-based individual plant detection and geometric parameter extraction in vineyards},
	volume = {14},
	issn = {1664-462X},
	url = {https://www.frontiersin.org/articles/10.3389/fpls.2023.1244384/full},
	doi = {10.3389/fpls.2023.1244384},
	abstract = {Accurately characterizing vineyard parameters is crucial for precise vineyard management and breeding purposes. Various macroscopic vineyard parameters are required to make informed management decisions, such as pesticide application, defoliation strategies, and determining optimal sugar content in each berry by assessing biomass. In this paper, we present a novel approach that utilizes point cloud data to detect trunk positions and extract macroscopic vineyard characteristics, including plant height, canopy width, and canopy volume. Our approach relies solely on geometric features and is compatible with different training systems and data collected using various 3D sensors. To evaluate the effectiveness and robustness of our proposed approach, we conducted extensive experiments on multiple grapevine rows trained in two different systems. Our method provides more comprehensive canopy characteristics than traditional manual measurements, which are not representative throughout the row. The experimental results demonstrate the accuracy and efficiency of our method in extracting vital macroscopic vineyard characteristics, providing valuable insights for yield monitoring, grape quality optimization, and strategic interventions to enhance vineyard productivity and sustainability.},
	pages = {1244384},
	journaltitle = {Frontiers in Plant Science},
	shortjournal = {Front. Plant Sci.},
	author = {Cantürk, Meltem and Zabawa, Laura and Pavlic, Diana and Dreier, Ansgar and Klingbeil, Lasse and Kuhlmann, Heiner},
	urldate = {2025-01-06},
	date = {2023-11-14},
	file = {Full Text:/Users/shrikar/Zotero/storage/79GSEXYN/Cantürk et al. - 2023 - UAV-based individual plant detection and geometric.pdf:application/pdf},
}

@misc{Segment_anything,
	title = {Segment Anything},
	url = {http://arxiv.org/abs/2304.02643},
	abstract = {We introduce the Segment Anything ({SA}) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model ({SAM}) and corresponding dataset ({SA}-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	number = {{arXiv}:2304.02643},
	publisher = {{arXiv}},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	urldate = {2024-10-22},
	date = {2023-04-05},
	eprinttype = {arxiv},
	eprint = {2304.02643 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/shrikar/Zotero/storage/D4X53BV3/Kirillov et al. - 2023 - Segment Anything.pdf:application/pdf},
}

@article{Robust_real_world,
	title = {Robust real-world point cloud registration by inlier detection},
	volume = {224},
	issn = {10773142},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1077314222001345},
	doi = {10.1016/j.cviu.2022.103556},
	pages = {103556},
	journaltitle = {Computer Vision and Image Understanding},
	shortjournal = {Computer Vision and Image Understanding},
	author = {Huang, Xiaoshui and Wang, Yangfu and Li, Sheng and Mei, Guofeng and Xu, Zongyi and Wang, Yucheng and Zhang, Jian and Bennamoun, Mohammed},
	urldate = {2024-10-22},
	date = {2022-11},
	langid = {english},
	keywords = {1 - {PreProcessing}},
}

@misc{Open3D_Library,
	title = {Open3D: A Modern Library for 3D Data Processing},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1801.09847},
	doi = {10.48550/ARXIV.1801.09847},
	shorttitle = {Open3D},
	abstract = {Open3D is an open-source library that supports rapid development of software that deals with 3D data. The Open3D frontend exposes a set of carefully selected data structures and algorithms in both C++ and Python. The backend is highly optimized and is set up for parallelization. Open3D was developed from a clean slate with a small and carefully considered set of dependencies. It can be set up on different platforms and compiled from source with minimal effort. The code is clean, consistently styled, and maintained via a clear code review mechanism. Open3D has been used in a number of published research projects and is actively deployed in the cloud. We welcome contributions from the open-source community.},
	publisher = {{arXiv}},
	author = {Zhou, Qian-Yi and Park, Jaesik and Koltun, Vladlen},
	urldate = {2024-10-22},
	date = {2018},
	note = {Version Number: 1},
	keywords = {{FOS}: Computer and information sciences, Robotics (cs.{RO}), Computer Vision and Pattern Recognition (cs.{CV}), 1 - {PreProcessing}, Graphics (cs.{GR})},
}

@inproceedings{Object_Detection,
	location = {Padang, Indonesia},
	title = {Object Detection Using Color Dissimilarity Based Segmentation Method},
	isbn = {978-1-7281-9567-4},
	url = {https://ieeexplore.ieee.org/document/9557737/},
	doi = {10.1109/iCAST51016.2020.9557737},
	eventtitle = {2020 International Conference on Applied Science and Technology ({iCAST})},
	pages = {366--370},
	publisher = {{IEEE}},
	author = {Gede Made Karma, I and Made Dwi Jendra Sulastra, I and Susanti, Jeni},
	urldate = {2024-06-04},
	date = {2020-10-24},
	keywords = {4 - Classification},
}

@article{PointGLR,
	title = {{PointGLR}: Unsupervised Structural Representation Learning of 3D Point Clouds},
	volume = {45},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {https://ieeexplore.ieee.org/document/9736689/},
	doi = {10.1109/TPAMI.2022.3159794},
	shorttitle = {{PointGLR}},
	pages = {2193--2207},
	number = {2},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	shortjournal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
	author = {Rao, Yongming and Lu, Jiwen and Zhou, Jie},
	urldate = {2024-06-28},
	date = {2023-02-01},
	keywords = {4 - Classification, 3 - Unsupervised Learning},
}

@article{Semantic_Image,
	title = {Semantic Image Segmentation and Object Labeling},
	volume = {17},
	issn = {1051-8215},
	url = {http://ieeexplore.ieee.org/document/4118230/},
	doi = {10.1109/TCSVT.2007.890636},
	pages = {298--312},
	number = {3},
	journaltitle = {{IEEE} Transactions on Circuits and Systems for Video Technology},
	shortjournal = {{IEEE} Trans. Circuits Syst. Video Technol.},
	author = {Athanasiadis, Thanos and Mylonas, Phivos and Avrithis, Yannis and Kollias, Stefanos},
	urldate = {2024-06-04},
	date = {2007-03},
	keywords = {3 - Unsupervised Learning},
}

@inproceedings{Point_cloud_seg_rgb,
	location = {Abu Dhabi, United Arab Emirates},
	title = {Point Cloud Segmentation using {RGB} Drone Imagery},
	isbn = {978-1-7281-6395-6},
	url = {https://ieeexplore.ieee.org/document/9191266/},
	doi = {10.1109/ICIP40778.2020.9191266},
	eventtitle = {2020 {IEEE} International Conference on Image Processing ({ICIP})},
	pages = {2750--2754},
	publisher = {{IEEE}},
	author = {{WuDunn}, Marc and Dunn, James and Zakhor, Avideh},
	urldate = {2024-06-04},
	date = {2020-10},
	keywords = {4 - Classification},
}

@article{Filtering_UAV,
	title = {Point cloud filtering on {UAV} based point cloud},
	volume = {133},
	issn = {02632241},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224118309357},
	doi = {10.1016/j.measurement.2018.10.013},
	pages = {99--111},
	journaltitle = {Measurement},
	shortjournal = {Measurement},
	author = {Zeybek, Mustafa and Şanlıoğlu, İsmail},
	urldate = {2024-06-04},
	date = {2019-02},
	langid = {english},
	keywords = {4 - Classification},
}

@inproceedings{Foldingnet,
	location = {Salt Lake City, {UT}},
	title = {{FoldingNet}: Point Cloud Auto-Encoder via Deep Grid Deformation},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8578127/},
	doi = {10.1109/CVPR.2018.00029},
	shorttitle = {{FoldingNet}},
	eventtitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {206--215},
	booktitle = {2018 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	publisher = {{IEEE}},
	author = {Yang, Yaoqing and Feng, Chen and Shen, Yiru and Tian, Dong},
	urldate = {2024-06-28},
	date = {2018-06},
	keywords = {3 - Unsupervised Learning},
	file = {Submitted Version:/Users/shrikar/Zotero/storage/IUHLBMN6/Yang et al. - 2018 - FoldingNet Point Cloud Auto-Encoder via Deep Grid.pdf:application/pdf},
}

@article{Evaluating_tree_detection,
	title = {Evaluating Tree Detection and Segmentation Routines on Very High Resolution {UAV} {LiDAR} Data},
	volume = {52},
	issn = {0196-2892, 1558-0644},
	url = {http://ieeexplore.ieee.org/document/6805152/},
	doi = {10.1109/TGRS.2014.2315649},
	pages = {7619--7628},
	number = {12},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	shortjournal = {{IEEE} Trans. Geosci. Remote Sensing},
	author = {Wallace, Luke and Lucieer, Arko and Watson, Christopher S.},
	urldate = {2024-06-04},
	date = {2014-12},
	keywords = {2 - Feature Extraction},
}

@article{trunk_point_plantation,
	title = {A tree detection method based on trunk point cloud section in dense plantation forest using drone {LiDAR} data},
	volume = {10},
	issn = {21975620},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2197562023000039},
	doi = {10.1016/j.fecs.2023.100088},
	pages = {100088},
	journaltitle = {Forest Ecosystems},
	shortjournal = {Forest Ecosystems},
	author = {Zhang, Yupan and Tan, Yiliu and Onda, Yuichi and Hashimoto, Asahi and Gomi, Takashi and Chiu, Chenwei and Inokoshi, Shodai},
	urldate = {2024-06-04},
	date = {2023},
	langid = {english},
	keywords = {2 - Feature Extraction},
}

@inproceedings{PCL,
	location = {Shanghai, China},
	title = {3D is here: Point Cloud Library ({PCL})},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-61284-386-5 978-1-61284-385-8},
	url = {https://ieeexplore.ieee.org/document/5980567/},
	doi = {10.1109/ICRA.2011.5980567},
	shorttitle = {3D is here},
	eventtitle = {2011 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	pages = {1--4},
	booktitle = {2011 {IEEE} International Conference on Robotics and Automation},
	publisher = {{IEEE}},
	author = {Rusu, Radu Bogdan and Cousins, Steve},
	urldate = {2024-06-11},
	date = {2011-05},
	keywords = {1 - {PreProcessing}},
	file = {Submitted Version:/Users/shrikar/Zotero/storage/A57CP97C/Rusu and Cousins - 2011 - 3D is here Point Cloud Library (PCL).pdf:application/pdf},
}

@inproceedings{Survey_point_cloud_seg,
	location = {Manila, Philippines},
	title = {3D point cloud segmentation: A survey},
	isbn = {978-1-4799-1201-8 978-1-4799-1198-1 978-1-4799-1199-8},
	url = {http://ieeexplore.ieee.org/document/6758588/},
	doi = {10.1109/RAM.2013.6758588},
	shorttitle = {3D point cloud segmentation},
	eventtitle = {2013 6th International Conference on Robotics, Automation and Mechatronics ({RAM})},
	pages = {225--230},
	booktitle = {2013 6th {IEEE} Conference on Robotics, Automation and Mechatronics ({RAM})},
	publisher = {{IEEE}},
	author = {Nguyen, Anh and Le, Bac},
	urldate = {2024-05-14},
	date = {2013-11},
	keywords = {1 - {PreProcessing}},
}

@inproceedings{PointNet,
	location = {Honolulu, {HI}},
	title = {{PointNet}: Deep Learning on Point Sets for 3D Classification and Segmentation},
	isbn = {978-1-5386-0457-1},
	url = {http://ieeexplore.ieee.org/document/8099499/},
	doi = {10.1109/CVPR.2017.16},
	shorttitle = {{PointNet}},
	eventtitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {77--85},
	booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {Charles, R. Qi and Su, Hao and Kaichun, Mo and Guibas, Leonidas J.},
	urldate = {2024-06-25},
	date = {2017-07},
	keywords = {4 - Classification, 2 - Feature Extraction},
	file = {Submitted Version:/Users/shrikar/Zotero/storage/HTPLFBSE/Charles et al. - 2017 - PointNet Deep Learning on Point Sets for 3D Class.pdf:application/pdf},
}

@article{Unsupervised_ground_filtering,
	title = {Unsupervised ground filtering of airborne-based 3D meshes using a robust cloth simulation},
	volume = {111},
	issn = {15698432},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1569843222000322},
	doi = {10.1016/j.jag.2022.102830},
	pages = {102830},
	journaltitle = {International Journal of Applied Earth Observation and Geoinformation},
	shortjournal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Yu, Dayu and He, Lianlian and Ye, Fan and Jiang, Liangcun and Zhang, Chenxiao and Fang, Zhe and Liang, Zheheng},
	urldate = {2024-07-08},
	date = {2022-07},
	langid = {english},
	keywords = {4 - Classification},
}

@inproceedings{Curvature_estimation_3d_point,
	title = {Curvature Estimation of 3D Point Cloud Surfaces Through the Fitting of Normal Section Curvatures},
	url = {https://www.semanticscholar.org/paper/Curvature-Estimation-of-3D-Point-Cloud-Surfaces-the-Zhang/8f479cdd86594aad9e9ec2fea50608c8480b6c5c},
	abstract = {As the technical development of laser scanning and image based modeling, more and more point cloud data are obtained to represent 3D geometric shapes of natural objects. Calculation of differential properties of 3D discrete geometry becomes one fundamental work. Through the relation of discrete normal curvatures and principal curvatures, a new algorithm is presented on estimating the principal curvatures and principal directions 3D point cloud surface. Based on the local fitting of each normal section circle properties with the position and the normal at a neighbor point, principal curvatures and principal directions are estimated from the contribution of these neighbor points. Optimization of this estimation is converted as a linear system by least squares fitting to all discrete normal curvatures corresponding to its neighbor points. A local feature curve, called as normal curvature index lines, is constructed to show the efficiency of this work. This curve is intuitive and equivalent to Dupin index line. Experiments are designed on Gaussian curvature, mean curvature and principal directions for an analytical surface and discrete surfaces of point cloud data. Experimental results show that this work is more advantageous than similar approaches, ad have applications to shape analysis and measurements.},
	author = {Zhang, Xiaopeng},
	urldate = {2024-08-14},
	date = {2008},
	keywords = {2 - Feature Extraction},
	file = {Full Text PDF:/Users/shrikar/Zotero/storage/84IV2JXE/Zhang - 2008 - Curvature Estimation of 3D Point Cloud Surfaces Th.pdf:application/pdf},
}

@inproceedings{PointClustering,
	location = {Vancouver, {BC}, Canada},
	title = {{PointClustering}: Unsupervised Point Cloud Pre-training using Transformation Invariance in Clustering},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-0129-8},
	url = {https://ieeexplore.ieee.org/document/10205041/},
	doi = {10.1109/CVPR52729.2023.02090},
	shorttitle = {{PointClustering}},
	eventtitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {21824--21834},
	booktitle = {2023 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	publisher = {{IEEE}},
	author = {Long, Fuchen and Yao, Ting and Qiu, Zhaofan and Li, Lusong and Mei, Tao},
	urldate = {2024-06-28},
	date = {2023-06},
	keywords = {3 - Unsupervised Learning},
}

@inproceedings{DBSCAN,
	location = {Rio de Janeiro, Brazil},
	title = {Traffic accident location study based on {AD}-{DBSCAN} Algorithm with Adaptive Parameters},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-3168-4},
	url = {https://ieeexplore.ieee.org/document/10152613/},
	doi = {10.1109/CSCWD57460.2023.10152613},
	eventtitle = {2023 26th International Conference on Computer Supported Cooperative Work in Design ({CSCWD})},
	pages = {1160--1165},
	booktitle = {2023 26th International Conference on Computer Supported Cooperative Work in Design ({CSCWD})},
	publisher = {{IEEE}},
	author = {Zhang, Xijun and Su, Jin and Zhang, Hong and Zhang, Xianli and Chen, Xuan and Cui, Yong},
	urldate = {2024-08-14},
	date = {2023-05-24},
	keywords = {3 - Unsupervised Learning, 5 - Validation},
}

@inproceedings{Silhouette_score,
	location = {sydney, Australia},
	title = {Cluster Quality Analysis Using Silhouette Score},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-7281-8206-3},
	url = {https://ieeexplore.ieee.org/document/9260048/},
	doi = {10.1109/DSAA49011.2020.00096},
	eventtitle = {2020 {IEEE} 7th International Conference on Data Science and Advanced Analytics ({DSAA})},
	pages = {747--748},
	booktitle = {2020 {IEEE} 7th International Conference on Data Science and Advanced Analytics ({DSAA})},
	publisher = {{IEEE}},
	author = {Shahapure, Ketan Rajshekhar and Nicholas, Charles},
	urldate = {2024-08-14},
	date = {2020-10},
	keywords = {5 - Validation},
	file = {Full Text:/Users/shrikar/Zotero/storage/L2PIFR4S/Shahapure and Nicholas - 2020 - Cluster Quality Analysis Using Silhouette Score.pdf:application/pdf},
}

@inproceedings{Davies-Bouldin,
	location = {Temuco},
	title = {New Version of Davies-Bouldin Index for Clustering Validation Based on Cylindrical Distance},
	isbn = {978-1-5090-0426-3},
	url = {https://ieeexplore.ieee.org/document/7814434/},
	doi = {10.1109/SCCC.2013.29},
	eventtitle = {2013 32nd International Conference of the Chilean Computer Science Society ({SCCC})},
	pages = {49--53},
	booktitle = {2013 32nd International Conference of the Chilean Computer Science Society ({SCCC})},
	publisher = {{IEEE}},
	author = {Rojas Thomas, Juan Carlos and Penas, Matilde Santos and Mora, Marco},
	urldate = {2024-08-14},
	date = {2013-11},
	keywords = {5 - Validation},
}

@article{GroundGrid,
	title = {{GroundGrid}: {LiDAR} Point Cloud Ground Segmentation and Terrain Estimation},
	volume = {9},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2377-3766, 2377-3774},
	url = {https://ieeexplore.ieee.org/document/10319084/},
	doi = {10.1109/LRA.2023.3333233},
	shorttitle = {{GroundGrid}},
	pages = {420--426},
	number = {1},
	journaltitle = {{IEEE} Robotics and Automation Letters},
	shortjournal = {{IEEE} Robot. Autom. Lett.},
	author = {Steinke, Nicolai and Goehring, Daniel and Rojas, Raúl},
	urldate = {2025-02-11},
	date = {2024-01},
}

@inproceedings{Optuna,
	location = {Anchorage {AK} {USA}},
	title = {Optuna: A Next-generation Hyperparameter Optimization Framework},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330701},
	doi = {10.1145/3292500.3330701},
	shorttitle = {Optuna},
	eventtitle = {{KDD} '19: The 25th {ACM} {SIGKDD} Conference on Knowledge Discovery and Data Mining},
	pages = {2623--2631},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on Knowledge Discovery \& Data Mining},
	publisher = {{ACM}},
	author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	urldate = {2025-04-17},
	date = {2019-07-25},
	langid = {english},
}

@article{CSF,
	title = {An Easy-to-Use Airborne {LiDAR} Data Filtering Method Based on Cloth Simulation},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/8/6/501},
	doi = {10.3390/rs8060501},
	abstract = {Separating point clouds into ground and non-ground measurements is an essential step to generate digital terrain models ({DTMs}) from airborne {LiDAR} (light detection and ranging) data. However, most filtering algorithms need to carefully set up a number of complicated parameters to achieve high accuracy. In this paper, we present a new filtering method which only needs a few easy-to-set integer and Boolean parameters. Within the proposed approach, a {LiDAR} point cloud is inverted, and then a rigid cloth is used to cover the inverted surface. By analyzing the interactions between the cloth nodes and the corresponding {LiDAR} points, the locations of the cloth nodes can be determined to generate an approximation of the ground surface. Finally, the ground points can be extracted from the {LiDAR} point cloud by comparing the original {LiDAR} points and the generated surface. Benchmark datasets provided by {ISPRS} (International Society for Photogrammetry and Remote Sensing) working Group {III}/3 are used to validate the proposed filtering method, and the experimental results yield an average total error of 4.58\%, which is comparable with most of the state-of-the-art filtering algorithms. The proposed easy-to-use filtering method may help the users without much experience to use {LiDAR} data and related technology in their own applications more easily.},
	pages = {501},
	number = {6},
	journaltitle = {Remote Sensing},
	shortjournal = {Remote Sensing},
	author = {Zhang, Wuming and Qi, Jianbo and Wan, Peng and Wang, Hongtao and Xie, Donghui and Wang, Xiaoyan and Yan, Guangjian},
	urldate = {2025-04-17},
	date = {2016-06-15},
	langid = {english},
	file = {Full Text:/Users/shrikar/Zotero/storage/Q587YTEK/Zhang et al. - 2016 - An Easy-to-Use Airborne LiDAR Data Filtering Method Based on Cloth Simulation.pdf:application/pdf},
}

@inproceedings{RANSAC,
	location = {Valletta, Malta},
	title = {Superpoints in {RANSAC} Planes: A New Approach for Ground Surface Extraction Exemplified on Point Classification and Context-aware Reconstruction:},
	isbn = {978-989-758-402-2},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0008895600250037},
	doi = {10.5220/0008895600250037},
	shorttitle = {Superpoints in {RANSAC} Planes},
	eventtitle = {15th International Conference on Computer Graphics Theory and Applications},
	pages = {25--37},
	booktitle = {Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
	publisher = {{SCITEPRESS} - Science and Technology Publications},
	author = {Bulatov, Dimitri and Stütz, Dominik and Lucks, Lukas and Weinmann, Martin},
	urldate = {2025-04-17},
	date = {2020},
}

@article{PointNet++,
	title = {An Improved {PointNet}++ Based Method for 3D Point Cloud Geometric Features Segmentation in Mechanical Parts},
	volume = {129},
	issn = {22128271},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2212827124011429},
	doi = {10.1016/j.procir.2024.10.006},
	pages = {25--30},
	journaltitle = {Procedia {CIRP}},
	shortjournal = {Procedia {CIRP}},
	author = {Zhang, Peng and Kong, Chao and Xu, Yuanping and Zhang, Chaolong and Jin, Jin and Li, Tukun and Jiang, Xiangqian and Tang, Dan},
	urldate = {2025-04-17},
	date = {2024},
	langid = {english},
}

@misc{ColoudCompare,
    key = CloudCompare (version 2.5) [GPL software]. (2025). Retrieved from http://www.cloudcompare.org/,
    note = 
}

@article{ClothSF,
	title = {An improved topographic mapping technique from airborne lidar: application in a forested hillside},
	volume = {34},
	issn = {0143-1161, 1366-5901},
	url = {https://www.tandfonline.com/doi/full/10.1080/01431161.2013.817710},
	doi = {10.1080/01431161.2013.817710},
	shorttitle = {An improved topographic mapping technique from airborne lidar},
	pages = {7293--7311},
	number = {20},
	journaltitle = {International Journal of Remote Sensing},
	shortjournal = {International Journal of Remote Sensing},
	author = {Lee, Jun-Hak and Biging, Gregory S. and Radke, John D. and Fisher, Joshua B.},
	urldate = {2025-04-20},
	date = {2013-10-20},
	langid = {english},
}


@ARTICLE{RANSAC,
  
AUTHOR={Khosla, Deepak  and Chen, Yang  and Kim, Kyungnam },
         
TITLE={A neuromorphic system for video object recognition},
        
JOURNAL={Frontiers in Computational Neuroscience},
        
VOLUME={Volume 8 - 2014},

YEAR={2014},

URL={https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2014.00147},

DOI={10.3389/fncom.2014.00147},

ISSN={1662-5188},

ABSTRACT={<p>Automated video object recognition is a topic of emerging importance in both defense and civilian applications. This work describes an accurate and low-power neuromorphic architecture and system for real-time automated video object recognition. Our system, Neuormorphic Visual Understanding of Scenes (NEOVUS), is inspired by computational neuroscience models of feed-forward object detection and classification pipelines for processing visual data. The NEOVUS architecture is inspired by the ventral (<italic>what</italic>) and dorsal (<italic>where</italic>) streams of the mammalian visual pathway and integrates retinal processing, object detection based on form and motion modeling, and object classification based on convolutional neural networks. The object recognition performance and energy use of the NEOVUS was evaluated by the Defense Advanced Research Projects Agency (DARPA) under the Neovision2 program using three urban area video datasets collected from a mix of stationary and moving platforms. These datasets are challenging and include a large number of objects of different types in cluttered scenes, with varying illumination and occlusion conditions. In a systematic evaluation of five different teams by DARPA on these datasets, the NEOVUS demonstrated the best performance with high object recognition accuracy and the lowest energy consumption. Its energy use was three orders of magnitude lower than two independent state of the art baseline computer vision systems. The dynamic power requirement for the complete system mapped to commercial off-the-shelf (COTS) hardware that includes a 5.6 Megapixel color camera processed by object detection and classification algorithms at 30 frames per second was measured at 21.7 Watts (W), for an effective energy consumption of 5.45 nanoJoules (nJ) per bit of incoming video. These unprecedented results show that the NEOVUS has the potential to revolutionize automated video object recognition toward enabling practical low-power and mobile video processing applications.</p>}}

@ARTICLE{dataset_align,
  author={Holz, Dirk and Ichim, Alexandru E. and Tombari, Federico and Rusu, Radu B. and Behnke, Sven},
  journal={IEEE Robotics & Automation Magazine}, 
  title={Registration with the Point Cloud Library: A Modular Framework for Aligning in 3-D}, 
  year={2015},
  volume={22},
  number={4},
  pages={110-124},
  keywords={Three-dimensional displays;Cloud computing;Iterative closest point algorithm;Open source software;Iterative methods;Robot sensing systems;Sensors},
  doi={10.1109/MRA.2015.2432331}}

@article{noisy_pcd,
title = {Extracting lines of curvature from noisy point clouds},
journal = {Computer-Aided Design},
volume = {41},
number = {4},
pages = {282-292},
year = {2009},
note = {Point-based Computational Techniques},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2008.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010448508002273},
author = {Evangelos Kalogerakis and Derek Nowrouzezahrai and Patricio Simari and Karan Singh},
keywords = {Lines of curvature, Robust curvature estimation, Point cloud denoising, Outlier rejection, Quad mesh construction},
abstract = {We present a robust framework for extracting lines of curvature from point clouds. First, we show a novel approach to denoising the input point cloud using robust statistical estimates of surface normal and curvature which automatically rejects outliers and corrects points by energy minimization. Then the lines of curvature are constructed on the point cloud with controllable density. Our approach is applicable to surfaces of arbitrary genus, with or without boundaries, and is statistically robust to noise and outliers while preserving sharp surface features. We show our approach to be effective over a range of synthetic and real-world input datasets with varying amounts of noise and outliers. The extraction of curvature information can benefit many applications in CAD, computer vision and graphics for point cloud shape analysis, recognition and segmentation. Here, we show the possibility of using the lines of curvature for feature-preserving mesh construction directly from noisy point clouds.}
}


@inproceedings{DBSCan_Grammarly,
	location = {Paris, France},
	title = {Modification of {DBSCAN} and application to range/Doppler/{DoA} measurements for pedestrian recognition with an automotive radar system},
	isbn = {978-2-87487-041-5},
	url = {http://ieeexplore.ieee.org/document/7346289/},
	doi = {10.1109/EuRAD.2015.7346289},
	eventtitle = {2015 European Radar Conference ({EuRAD})},
	pages = {269--272},
	booktitle = {2015 European Radar Conference ({EuRAD})},
	publisher = {{IEEE}},
	author = {Wagner, Thomas and Feger, Reinhard and Stelzer, Andreas},
	urldate = {2025-04-23},
	date = {2015-09},
}
